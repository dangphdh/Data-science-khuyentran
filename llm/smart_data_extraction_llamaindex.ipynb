{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction â€” Stop Copying Receipts by Hand\n",
    "\n",
    "Manual data entry from receipts, invoices, and contracts wastes hours and introduces errors. What if you could automatically extract structured data from these documents in minutes?\n",
    "\n",
    "In this article, you'll learn how to transform receipt images into structured data using LlamaIndex, then export the results to a spreadsheet for analysis.\n",
    "\n",
    "\n",
    "## What You Will Learn\n",
    "\n",
    "- Convert scanned receipts to structured data with LlamaParse and Pydantic models\n",
    "- Validate extraction accuracy by comparing results against ground truth annotations\n",
    "- Fix parsing errors by preprocessing low-quality images\n",
    "- Export clean receipt data to spreadsheet format\n",
    "\n",
    "## Introduction to LlamaIndex\n",
    "\n",
    "[LlamaIndex](https://www.llamaindex.ai/) is a framework that connects LLMs with your data through three core capabilities:\n",
    "\n",
    "1. **Data ingestion**: Built-in readers for PDFs, images, web pages, and databases that automatically parse content into processable nodes.\n",
    "2. **Structured extraction**: LLM-powered conversion of unstructured text into Pydantic models with automatic validation.\n",
    "3. **Retrieval and indexing**: Vector stores and semantic search that enable context-augmented queries over your documents.\n",
    "\n",
    "It eliminates boilerplate code for loading, parsing, and querying data, letting you focus on building LLM applications.\n",
    "\n",
    "The table below compares LlamaIndex with two other popular frameworks for LLM applications:\n",
    "\n",
    "| Framework | Purpose | Best For |\n",
    "| --------- | ------- | -------- |\n",
    "| **LlamaIndex** | Document ingestion and structured extraction | Converting unstructured documents into query-ready data |\n",
    "| **LangChain** | LLM orchestration and tool integration | Building conversational agents with multiple LLM calls |\n",
    "| **LangGraph** | Stateful workflow management | Coordinating long-running, multi-agent processes |\n",
    "\n",
    "### Installation\n",
    "\n",
    "Start with installing the required packages for this tutorial, including:\n",
    "\n",
    "- llama-index: Core LlamaIndex framework with base indexing and retrieval functionality\n",
    "- llama-parse: Document parsing service for PDFs, images, and complex layouts\n",
    "- llama-index-program-openai: OpenAI integration for structured data extraction with Pydantic\n",
    "- python-dotenv: Load environment variables from .env files\n",
    "- rapidfuzz: Fuzzy string matching library for comparing company names with minor variations\n",
    "\n",
    "```bash\n",
    "pip install llama-index llama-parse llama-index-program-openai python-dotenv rapidfuzz\n",
    "```\n",
    "\n",
    "### Environment Setup\n",
    "\n",
    "Create a `.env` file to store your API keys:\n",
    "\n",
    "```text\n",
    "# .env\n",
    "LLAMA_CLOUD_API_KEY=\"your-llama-parse-key\"\n",
    "OPENAI_API_KEY=\"your-openai-key\"\n",
    "```\n",
    "\n",
    "Get your API keys from:\n",
    "- **LlamaParse API**: [cloud.llamaindex.ai](https://cloud.llamaindex.ai)\n",
    "- **OpenAI API**: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)\n",
    "\n",
    "Load the environment variables from the `.env` file with `load_dotenv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the default LLM with `Settings`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "Settings.context_window = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Settings` stores global defaults so every query engine and program reuses the same LLM configuration. Keeping temperature at 0 nudges the model to return deterministic, structured outputs.\n",
    "\n",
    "## Basic Image Processing with LlamaParse\n",
    "\n",
    "In this tutorial, we will use the [SROIE Dataset v2](https://www.kaggle.com/datasets/urbikn/sroie-datasetv2) from Kaggle. This dataset contains real-world receipt scans from the ICDAR 2019 competition.\n",
    "\n",
    "You can download the dataset directly from Kaggle's website or use the Kaggle CLI: \n",
    "\n",
    "```bash\n",
    "# Install the Kaggle CLI once\n",
    "uv pip install kaggle\n",
    "\n",
    "# Configure Kaggle credentials (run once per environment)\n",
    "export KAGGLE_USERNAME=your_username\n",
    "export KAGGLE_KEY=your_api_key\n",
    "\n",
    "# Create a workspace folder and download the full archive (~1 GB)\n",
    "mkdir -p data\n",
    "kaggle datasets download urbikn/sroie-datasetv2 -p data\n",
    "\n",
    "# Extract everything and inspect a few image files\n",
    "unzip -q -o data/sroie-datasetv2.zip -d data\n",
    "find data/SROIE2019 -maxdepth 3 -type f -name \"*.jpg\" | head\n",
    "```\n",
    "\n",
    "This tutorial uses data from the `data/SROIE2019/train/` directory, which contains:\n",
    "\n",
    "- `img`: Original receipt images\n",
    "- `entities`: Ground truth annotations for validation\n",
    "\n",
    "Load the first 10 receipts into a list of paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "receipt_dir = Path(\"data/SROIE2019/train/img\")\n",
    "num_receipts = 10\n",
    "receipt_paths = sorted(receipt_dir.glob(\"*.jpg\"))[:num_receipts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first receipt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "first_receipt_path = receipt_paths[0]\n",
    "Image(filename=first_receipt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use `LlamaParse` to convert the first receipt into markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "\n",
    "# Parse receipts with LlamaParse\n",
    "parser = LlamaParse(\n",
    "    api_key=os.environ[\"LLAMA_CLOUD_API_KEY\"],\n",
    "    result_type=\"markdown\",  # Output format\n",
    "    num_workers=4,  # Number of parallel workers for faster processing\n",
    "    language=\"en\",  # Language hint for OCR accuracy\n",
    "    skip_diagonal_text=True,  # Ignore rotated or diagonal text\n",
    ")\n",
    "first_receipt = parser.load_data(first_receipt_path)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the markdown for the first receipt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first receipt\n",
    "preview = \"\\n\".join(first_receipt.text.splitlines()[:10])\n",
    "print(preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlamaParse successfully converts receipt images to text, but there is no structure: vendor names, dates, and totals are all mixed together in plain text. This format is not ideal for exporting to spreadsheets or analytics tools for further analysis.\n",
    "\n",
    "The next section uses Pydantic models to extract structured fields like `company`, `total`, and `purchase_date` automatically.\n",
    "\n",
    "## Structured Data Extraction with Pydantic\n",
    "\n",
    "[Pydantic](https://docs.pydantic.dev/) is a Python library that uses type hints for data validation and automatic type conversion. By defining a receipt schema once, you can extract consistent structured data from receipts regardless of their format or layout.\n",
    "\n",
    "Start by defining two Pydantic models that represent receipt structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field, ValidationInfo, model_validator\n",
    "\n",
    "\n",
    "class ReceiptItem(BaseModel):\n",
    "    \"\"\"Represents a single line item extracted from a receipt.\"\"\"\n",
    "\n",
    "    description: str = Field(description=\"Item name exactly as shown on the receipt\")\n",
    "    quantity: int = Field(default=1, ge=1, description=\"Integer quantity of the item\")\n",
    "    unit_price: Optional[float] = Field(\n",
    "        default=None, ge=0, description=\"Price per unit in the receipt currency\"\n",
    "    )\n",
    "    discount_amount: float = Field(\n",
    "        default=0.0, ge=0, description=\"Discount applied to this line item\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Receipt(BaseModel):\n",
    "    \"\"\"Structured fields extracted from a retail receipt.\"\"\"\n",
    "\n",
    "    company: str = Field(description=\"Business or merchant name\")\n",
    "    purchase_date: Optional[date] = Field(\n",
    "        default=None, description=\"Date in YYYY-MM-DD format\"\n",
    "    )\n",
    "    address: Optional[str] = Field(default=None, description=\"Address of the business\")\n",
    "    total: float = Field(description=\"Final charged amount\")\n",
    "    items: List[ReceiptItem] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an `OpenAIPydanticProgram` that instructs the LLM to extract data according to our `Receipt` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.program.openai import OpenAIPydanticProgram\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are extracting structured data from a receipt.\n",
    "Use the provided text to populate the Receipt model.\n",
    "Interpret every receipt date as day-first.\n",
    "If a field is missing, return null.\n",
    "\n",
    "{context_str}\n",
    "\"\"\"\n",
    "\n",
    "receipt_program = OpenAIPydanticProgram.from_defaults(\n",
    "    output_cls=Receipt,\n",
    "    llm=Settings.llm,\n",
    "    prompt_template_str=prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the first parsed document to make sure everything works before scaling to the full batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the first receipt\n",
    "structured_first_receipt = receipt_program(context_str=first_receipt.text)\n",
    "\n",
    "# Print the receipt as a JSON string for better readability\n",
    "print(structured_first_receipt.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlamaIndex populates the Pydantic schema with extracted values:\n",
    "\n",
    "- `company` - Vendor name from the receipt header\n",
    "- `purchase_date` - Parsed date (2018-12-25)\n",
    "- `total` - Final amount (9.0)\n",
    "- `items` - Line items with description, quantity, and price\n",
    "\n",
    "Now that the extraction works, let's scale it to process all receipts in a batch. The function uses each receipt's filename as a unique identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_documents(paths: List[str], prompt: str, id_column: str = \"receipt_id\") -> List[dict]:\n",
    "    \"\"\"Extract structured data from documents using LlamaParse and LLM.\"\"\"\n",
    "    results: List[dict] = []\n",
    "\n",
    "    # Initialize parser with OCR settings\n",
    "    parser = LlamaParse(\n",
    "        api_key=os.environ[\"LLAMA_CLOUD_API_KEY\"],\n",
    "        result_type=\"markdown\",\n",
    "        num_workers=4,\n",
    "        language=\"en\",\n",
    "        skip_diagonal_text=True,\n",
    "    )\n",
    "\n",
    "    # Convert images to markdown text\n",
    "    documents = parser.load_data(paths)\n",
    "\n",
    "    # Create structured extraction program\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        output_cls=Receipt,\n",
    "        llm=Settings.llm,\n",
    "        prompt_template_str=prompt,\n",
    "    )\n",
    "\n",
    "    # Extract structured data from each document\n",
    "    for path, doc in zip(paths, documents):\n",
    "        document_id = Path(path).stem\n",
    "        parsed_document = program(context_str=doc.text)\n",
    "        results.append(\n",
    "            {\n",
    "                id_column: document_id,\n",
    "                \"data\": parsed_document,\n",
    "            }\n",
    "        )\n",
    "    return results\n",
    "\n",
    "# Extract structured data from all receipts\n",
    "structured_receipts = extract_documents(receipt_paths, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the extracted receipts into a DataFrame for easier inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def transform_receipt_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Apply standard transformations to receipt DataFrame columns.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"company\"] = df[\"company\"].str.upper()\n",
    "    df[\"total\"] = pd.to_numeric(df[\"total\"], errors=\"coerce\")\n",
    "    df[\"purchase_date\"] = pd.to_datetime(\n",
    "        df[\"purchase_date\"], errors=\"coerce\", dayfirst=True\n",
    "    ).dt.date\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_extracted_df(records: List[dict], id_column: str = \"receipt_id\") -> pd.DataFrame:\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                id_column: record[id_column],\n",
    "                \"company\": record[\"data\"].company,\n",
    "                \"total\": record[\"data\"].total,\n",
    "                \"purchase_date\": record[\"data\"].purchase_date,\n",
    "            }\n",
    "            for record in records\n",
    "        ]\n",
    "    )\n",
    "    return transform_receipt_columns(df)\n",
    "\n",
    "\n",
    "extracted_df = create_extracted_df(structured_receipts)\n",
    "extracted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most receipts are extracted correctly, but receipt X51005200938 shows issues:\n",
    "\n",
    "- The company name is incomplete (\"TH MNAN\")\n",
    "- Total is 0 instead of the actual amount\n",
    "- Date (2023-10-11) appears incorrect\n",
    "\n",
    "## Compare Extraction with Ground Truth\n",
    "\n",
    "To verify the extraction accuracy, load the ground-truth annotations from `data/SROIE2019/train/entities`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_date(value: str) -> str:\n",
    "    \"\"\"Normalize date strings to consistent format.\"\"\"\n",
    "    value = (value or \"\").strip()\n",
    "    if not value:\n",
    "        return value\n",
    "    # Convert hyphens to slashes\n",
    "    value = value.replace(\"-\", \"/\")\n",
    "    parts = value.split(\"/\")\n",
    "    # Convert 2-digit years to 4-digit (e.g., 18 -> 2018)\n",
    "    if len(parts[-1]) == 2:\n",
    "        parts[-1] = f\"20{parts[-1]}\"\n",
    "    return \"/\".join(parts)\n",
    "\n",
    "\n",
    "def create_ground_truth_df(\n",
    "    label_paths: List[str], id_column: str = \"receipt_id\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Create ground truth DataFrame from label JSON files.\"\"\"\n",
    "    records = []\n",
    "    # Load each JSON file and extract key fields\n",
    "    for path in label_paths:\n",
    "        payload = pd.read_json(Path(path), typ=\"series\").to_dict()\n",
    "        records.append(\n",
    "            {\n",
    "                id_column: Path(path).stem,\n",
    "                \"company\": payload.get(\"company\"),\n",
    "                \"total\": payload.get(\"total\"),\n",
    "                \"purchase_date\": normalize_date(payload.get(\"date\")),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    # Apply same transformations as extracted data\n",
    "    return transform_receipt_columns(df)\n",
    "\n",
    "\n",
    "# Load ground truth annotations\n",
    "label_dir = Path(\"data/SROIE2019/train/entities\")\n",
    "label_paths = sorted(label_dir.glob(\"*.txt\"))[:num_receipts]\n",
    "\n",
    "ground_truth_df = create_ground_truth_df(label_paths)\n",
    "ground_truth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's validate extraction accuracy by comparing results against ground truth.\n",
    "\n",
    "Company names often have minor variations (spacing, punctuation, extra characters), so we'll use [fuzzy matching](https://codecut.ai/text-similarity-fuzzy-matching-guide/) to tolerate these formatting differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "\n",
    "\n",
    "def fuzzy_match_score(text1: str, text2: str) -> int:\n",
    "    \"\"\"Calculate fuzzy match score between two strings.\"\"\"\n",
    "    return fuzz.token_set_ratio(str(text1), str(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the fuzzy matching with sample company names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearly identical strings score high\n",
    "print(f\"Score: {fuzzy_match_score('BOOK TA K SDN BHD', 'BOOK TA .K SDN BHD'):.2f}\")\n",
    "\n",
    "# Different punctuation still matches well\n",
    "print(f\"Score: {fuzzy_match_score('MR D.I.Y. JOHOR', 'MR DIY JOHOR'):.2f}\")\n",
    "\n",
    "# Completely different strings score low\n",
    "print(f\"Score: {fuzzy_match_score('ABC TRADING', 'XYZ COMPANY'):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a comparison function that merges extracted and ground truth data, then applies fuzzy matching for company names and exact matching for numeric fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_receipts(\n",
    "    extracted_df: pd.DataFrame,\n",
    "    ground_truth_df: pd.DataFrame,\n",
    "    id_column: str,\n",
    "    fuzzy_match_cols: List[str],\n",
    "    exact_match_cols: List[str],\n",
    "    fuzzy_threshold: int = 80,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compare extracted and ground truth data with explicit column specifications.\"\"\"\n",
    "    comparison_df = extracted_df.merge(\n",
    "        ground_truth_df,\n",
    "        on=id_column,\n",
    "        how=\"inner\",\n",
    "        suffixes=(\"_extracted\", \"_truth\"),\n",
    "    )\n",
    "\n",
    "    # Fuzzy matching\n",
    "    for col in fuzzy_match_cols:\n",
    "        extracted_col = f\"{col}_extracted\"\n",
    "        truth_col = f\"{col}_truth\"\n",
    "        comparison_df[f\"{col}_score\"] = comparison_df.apply(\n",
    "            lambda row: fuzzy_match_score(row[extracted_col], row[truth_col]),\n",
    "            axis=1,\n",
    "        )\n",
    "        comparison_df[f\"{col}_match\"] = comparison_df[f\"{col}_score\"] >= fuzzy_threshold\n",
    "\n",
    "    # Exact matching\n",
    "    for col in exact_match_cols:\n",
    "        extracted_col = f\"{col}_extracted\"\n",
    "        truth_col = f\"{col}_truth\"\n",
    "        comparison_df[f\"{col}_match\"] = (\n",
    "            comparison_df[extracted_col] == comparison_df[truth_col]\n",
    "        )\n",
    "\n",
    "    return comparison_df\n",
    "\n",
    "\n",
    "comparison_df = compare_receipts(\n",
    "    extracted_df,\n",
    "    ground_truth_df,\n",
    "    id_column=\"receipt_id\",\n",
    "    fuzzy_match_cols=[\"company\"],\n",
    "    exact_match_cols=[\"total\", \"purchase_date\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect any rows where the company, total, or purchase-date checks fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mismatch_rows(comparison_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Get mismatched rows, excluding match indicator columns.\"\"\"\n",
    "    # Extract match columns and data columns\n",
    "    match_columns = [col for col in comparison_df.columns if col.endswith(\"_match\")]\n",
    "    data_columns = sorted([col for col in comparison_df.columns if col.endswith(\"_extracted\") or col.endswith(\"_truth\")])\n",
    "\n",
    "    # Check for rows where not all matches are True\n",
    "    has_mismatch = comparison_df[match_columns].all(axis=1).eq(False)\n",
    "\n",
    "    return comparison_df[has_mismatch][data_columns]\n",
    "\n",
    "\n",
    "mismatch_df = get_mismatch_rows(comparison_df)\n",
    "\n",
    "\n",
    "mismatch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms what we saw earlier. All receipts match the ground truth annotations except for receipt ID X51005200938 for the following fields:\n",
    "\n",
    "- Company name\n",
    "- Total\n",
    "- Purchase date\n",
    "\n",
    "Let's take a closer look at this receipt to see if we can identify the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "\n",
    "file_to_inspect = receipt_dir / \"X51005200938.jpg\"\n",
    "\n",
    "display.Image(filename=file_to_inspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This receipt appears smaller than the others in the dataset, which may affect OCR readability. In the next section, we will scale up the receipt to improve the extraction.\n",
    "\n",
    "\n",
    "## Process the Images for Better Extraction\n",
    "\n",
    "Create a function to scale up the receipt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def scale_image(image_path: Path, output_dir: Path, scale_factor: int = 3) -> Path:\n",
    "    \"\"\"Scale up an image using high-quality resampling.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the original image\n",
    "        output_dir: Directory to save the scaled image\n",
    "        scale_factor: Factor to scale up the image (default: 3x)\n",
    "\n",
    "    Returns:\n",
    "        Path to the scaled image\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Scale up the image using high-quality resampling\n",
    "    new_size = (img.width * scale_factor, img.height * scale_factor)\n",
    "    img_resized = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Save to output directory with same filename\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_path = output_dir / image_path.name\n",
    "    img_resized.save(output_path, quality=95)\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function to the problematic receipt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_receipt_path = receipt_dir / \"X51005200938.jpg\"\n",
    "adjusted_receipt_dir = Path(\"data/SROIE2019/train/img_adjusted\")\n",
    "\n",
    "scaled_image_path = scale_image(problematic_receipt_path, adjusted_receipt_dir, scale_factor=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the structured data from the scaled image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_structured_receipts = extract_documents([scaled_image_path], prompt)\n",
    "problematic_extracted_df = create_extracted_df(problematic_structured_receipts)\n",
    "\n",
    "problematic_extracted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Scaling fixes the extraction. Company name and purchase date are now accurate. The total is 112.46 vs 112.45, acceptable since 112.45 actually looks like 112.46 when printed on the receipt.\n",
    "\n",
    "## Export Clean Data to CSV or Excel\n",
    "\n",
    "Apply the scaling fix to all receipts. Copy the remaining images to the processed directory, excluding the already-scaled receipt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "clean_receipt_paths = [scaled_image_path]\n",
    "# Copy all receipts except the already processed one\n",
    "for receipt_path in receipt_paths:\n",
    "    if receipt_path != problematic_receipt_path:  # Skip the already scaled image\n",
    "        output_path = adjusted_receipt_dir / receipt_path.name\n",
    "        shutil.copy2(receipt_path, output_path)\n",
    "        clean_receipt_paths.append(output_path)\n",
    "        print(f\"Copied {receipt_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the pipeline again with the processed images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_structured_receipts = extract_documents(clean_receipt_paths, prompt)\n",
    "clean_extracted_df = create_extracted_df(clean_structured_receipts)\n",
    "clean_extracted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! All receipts now match the ground truth annotations.\n",
    "\n",
    "Now we can export the dataset to a spreadsheet with just a few lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Export to CSV\n",
    "output_path = Path(\"reports/receipts.csv\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "clean_extracted_df.to_csv(output_path, index=False)\n",
    "print(f\"Exported {len(clean_extracted_df)} receipts to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exported data can now be imported into spreadsheet applications, analytics tools, or business intelligence platforms.\n",
    "\n",
    "## Try It Yourself\n",
    "\n",
    "The concepts from this tutorial are available as a reusable pipeline in [this GitHub repository](https://github.com/CodeCutTech/Data-science/tree/master/llm/smart_data_extraction_llamaindex). The code includes:\n",
    "\n",
    "- **Generic pipeline** ([`document_extraction_pipeline.py`](https://github.com/CodeCutTech/Data-science/blob/master/llm/smart_data_extraction_llamaindex/document_extraction_pipeline.py)): Reusable extraction function that works with any Pydantic schema\n",
    "- **Receipt pipeline** ([`extract_receipts_pipeline.py`](https://github.com/CodeCutTech/Data-science/blob/master/llm/smart_data_extraction_llamaindex/extract_receipts_pipeline.py)): Complete example with Receipt schema, image scaling, and data transformations\n",
    "\n",
    "Run the receipt extraction example:\n",
    "\n",
    "```bash\n",
    "uv run extract_receipts_pipeline.py\n",
    "```\n",
    "\n",
    "Or create your own extractor by importing `extract_structured_data()` and providing your custom Pydantic schema, extraction prompt, and optional preprocessing functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
