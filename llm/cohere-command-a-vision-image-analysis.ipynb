{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Chart Analysis with SmolVLM\n",
    "\n",
    "This notebook demonstrates how to automate chart analysis using SmolVLM, a lightweight multimodal AI model from Hugging Face.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Install required packages:\n",
    "```bash\n",
    "pip install transformers>=4.45.0 pillow torch gradio\n",
    "```\n",
    "\n",
    "## What You'll Learn\n",
    "- Load and use SmolVLM for visual analysis\n",
    "- Analyze charts with natural language queries  \n",
    "- Extract insights from documents and receipts\n",
    "- Build an interactive web dashboard\n",
    "\n",
    "\n",
    "```python\n",
    "# Current manual process: time-consuming chart analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load sales data and create visualizations\n",
    "df = pd.read_csv(\"quarterly_sales.csv\")\n",
    "charts = [\n",
    "    df.groupby('region').sum().plot(kind='bar'),\n",
    "    df.plot(x='date', y='revenue', kind='line'),\n",
    "    df.corr().style.background_gradient()  # Correlation heatmap\n",
    "]\n",
    "\n",
    "# Manual analysis required for each chart:\n",
    "# 1. Open and examine each visualization\n",
    "# 2. Identify patterns and trends visually\n",
    "# 3. Extract key insights manually\n",
    "# 4. Document findings for stakeholders\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated insight extraction with human oversight changes this dynamic. Use AI to quickly analyze visualizations and generate initial insights, then review and refine the output.\n",
    "\n",
    "## Introduction to SmolVLM\n",
    "\n",
    "[SmolVLM](https://huggingface.co/HuggingFaceTB/SmolVLM-500M-Instruct) enables this workflow by combining image analysis with natural language processing. This lightweight multimodal AI model, hosted on Hugging Face, processes images and text together for visual question-answering tasks.\n",
    "\n",
    "SmolVLM excels at:\n",
    "- Chart and graph analysis\n",
    "- Document understanding\n",
    "- Visual question answering\n",
    "- Image content summarization\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "SmolVLM eliminates the complexity of traditional image analysis by enabling direct natural language queries about visual content.\n",
    "\n",
    "Let's start by loading the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "\n",
    "# Load the processor and model\n",
    "model_id = \"HuggingFaceTB/SmolVLM-500M-Instruct\"\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Move model to available device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SmolVLM setup explained:\n",
    "\n",
    "- `AutoProcessor`: Converts images and text into format the model understands\n",
    "- `AutoModelForVision2Seq`: Loads the actual SmolVLM neural network weights\n",
    "- `torch.float16`: Uses half-precision to reduce memory usage by 50%\n",
    "- `Device detection`: Automatically uses GPU if available for faster inference\n",
    "\n",
    "Now, let's create a helper function to analyze a single image with a natural language question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_with_smolvlm(image, question, max_tokens=200):\n",
    "    \"\"\"Analyze an image with SmolVLM using a natural language question.\"\"\"\n",
    "    # Format input as chat conversation\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": question}\n",
    "        ]\n",
    "    }]\n",
    "\n",
    "    # Convert to model input format\n",
    "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(text=prompt, images=[image], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate response\n",
    "    generated_ids = model.generate(\n",
    "        **inputs, max_new_tokens=max_tokens, do_sample=True, temperature=0.3\n",
    "    )\n",
    "\n",
    "    # Extract and return the response text\n",
    "    response = processor.batch_decode(\n",
    "        generated_ids[:, inputs.input_ids.shape[1]:], skip_special_tokens=True\n",
    "    )[0]\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above does the following:\n",
    "\n",
    "- `apply_chat_template`: Formats the conversation for SmolVLM's expected input structure\n",
    "- `processor()`: Tokenizes text and preprocesses images into tensors\n",
    "- `model.generate()`: Runs the actual AI inference with configurable parameters\n",
    "- `batch_decode()`: Converts model output tokens back to readable text\n",
    "\n",
    "Next, create a helper function to analyze multiple questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_qa_results(questions, answers, separator_length=40):\n",
    "    \"\"\"Print question and answer pairs with formatted output.\"\"\"\n",
    "    for question, answer in zip(questions, answers, strict=False):\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Answer: {answer}\")\n",
    "        print(\"-\" * separator_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chart Analysis\n",
    "\n",
    "Let's put our helper function to work by analyzing a real heatmap using natural language queries.\n",
    "\n",
    "We'll analyze this correlation heatmap:\n",
    "\n",
    "![Heatmap showing correlation matrix with color-coded values](https://codecut.ai/wp-content/uploads/2025/08/heatmap.png)\n",
    "\n",
    "Here are the questions we'll ask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a complex chart for analysis - financial correlation heatmap\n",
    "image_url = (\n",
    "    \"https://eodhd.com/financial-academy/wp-content/uploads/2023/12/heatmap_sector.png\"\n",
    ")\n",
    "image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "\n",
    "# Ask questions about the chart\n",
    "questions = [\n",
    "    \"What type of chart is this?\",\n",
    "    \"What are the main trends shown in this visualization?\",\n",
    "    \"What insights can you derive from this data?\",\n",
    "]\n",
    "\n",
    "answers = [analyze_image_with_smolvlm(image, q) for q in questions]\n",
    "print_qa_results(questions, answers, separator_length=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model provides direct answers about chart type, trends, and insights without requiring manual preprocessing or specialized analysis tools.\n",
    "\n",
    "## Document Understanding\n",
    "\n",
    "SmolVLM excels at extracting information from documents, receipts, and forms. Let's test this with a receipt:\n",
    "\n",
    "![Receipt](https://codecut.ai/wp-content/uploads/2025/08/receipt-scaled.png)\n",
    "\n",
    "and ask the following questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a receipt or invoice\n",
    "receipt_url = \"https://raw.githubusercontent.com/mistralai/cookbook/main/mistral/ocr/receipt.png\"\n",
    "receipt_image = Image.open(requests.get(receipt_url, stream=True).raw)\n",
    "\n",
    "# Document analysis questions\n",
    "document_questions = [\n",
    "    \"What type of document is this?\",\n",
    "    \"What is the total amount?\",\n",
    "    \"What items can you identify?\",\n",
    "]\n",
    "\n",
    "answers = [analyze_image_with_smolvlm(receipt_image, q, max_tokens=150) for q in document_questions]\n",
    "print_qa_results(document_questions, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Content Summarization\n",
    "\n",
    "We can also use SmolVLM to generate a summary of an image.\n",
    "\n",
    "Let's use the following image:\n",
    "\n",
    "![Street scene](https://codecut.ai/wp-content/uploads/2025/08/street.jpeg)\n",
    "\n",
    "and ask the following questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a street scene\n",
    "street_url = \"https://images.unsplash.com/photo-1449824913935-59a10b8d2000?w=500\"\n",
    "street_image = Image.open(requests.get(street_url, stream=True).raw)\n",
    "\n",
    "# Summarization prompts\n",
    "summary_prompts = [\n",
    "    \"What's the main activity happening here?\",\n",
    "    \"Summarize the key elements of this scene\"\n",
    "]\n",
    "\n",
    "answers = [analyze_image_with_smolvlm(street_image, q, max_tokens=250) for q in summary_prompts]\n",
    "print_qa_results(summary_prompts, answers, separator_length=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Business Intelligence with Chart Analysis\n",
    "\n",
    "See how SmolVLM integrates into a real data analysis workflow. We'll create a sales performance chart and then analyze it with natural language queries.\n",
    "\n",
    "First, generate sample sales data and create the visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate quarterly sales data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Quarter\": [\"Q1 2024\", \"Q2 2024\", \"Q3 2024\", \"Q4 2024\"],\n",
    "    \"Product A\": [45000, 52000, 48000, 61000],\n",
    "    \"Product B\": [38000, 41000, 39000, 44000],\n",
    "    \"Product C\": [23000, 28000, 32000, 35000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index(\"Quarter\").plot(kind=\"bar\", figsize=(10, 6))\n",
    "plt.title(\"Quarterly Sales Performance by Product\")\n",
    "plt.ylabel(\"Sales ($)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\"sales_chart.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now analyze the chart with SmolVLM using targeted business questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the chart we just created\n",
    "chart_image = Image.open(\"sales_chart.png\")\n",
    "\n",
    "questions = [\n",
    "    \"What quarter had the best overall performance?\",\n",
    "    \"Are there any concerning trends I should investigate?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    answer = analyze_image_with_smolvlm(chart_image, question)\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow demonstrates SmolVLM's value in everyday data analysis: create visualizations with your preferred tools, then get instant insights through natural language queries.\n",
    "\n",
    "## Building a Web Dashboard\n",
    "\n",
    "To make chart analysis accessible for non-technical stakeholders, you can create an interactive web dashboard using [Gradio](https://gradio.app/). This Python framework enables rapid deployment of machine learning applications with just a few lines of code.\n",
    "\n",
    "Next, create a dashboard function that combines image upload with question input. This function uses the SmolVLM helper we defined earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dashboard_analysis(image, question):\n",
    "    if image is None:\n",
    "        return \"Please upload an image to analyze.\"\n",
    "\n",
    "    # Use the analyze_image_with_smolvlm function from earlier in the article\n",
    "    return analyze_image_with_smolvlm(image, question, max_tokens=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running this dashboard code independently, make sure to include the model loading and helper function from the \"Getting Started\" section above.\n",
    "\n",
    "The function handles image uploads and passes user questions directly to SmolVLM. Now build the Gradio interface with three components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "dashboard = gr.Interface(\n",
    "    fn=dashboard_analysis,\n",
    "    inputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Upload Chart or Visualization\"),\n",
    "        gr.Textbox(value=\"What are the key trends in this chart?\", label=\"Ask a Question\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Analysis Results\"),\n",
    "    title=\"SmolVLM Chart Analysis Dashboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the dashboard to make it accessible to your team:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard.launch(share=True)  # share=True creates public link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dashboard provides a clean interface where users upload charts and ask questions in natural language.\n",
    "\n",
    "![SmolVLM Chart Analysis Dashboard](https://codecut.ai/wp-content/uploads/2025/08/chart_analysis.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/Users/khuyentran/codecut_content/codecut_articles/.venv/share/jupyter/kernels/python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
