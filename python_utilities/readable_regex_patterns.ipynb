{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "Faker.seed(40)\n",
    "\n",
    "# Define phone patterns\n",
    "phone_patterns = [\"(###)###-####\", \"###-###-####\", \"### ### ####\", \"###.###.####\"]\n",
    "\n",
    "# Define email TLDs\n",
    "email_tlds = [\".com\", \".org\", \".io\", \".net\"]\n",
    "\n",
    "# Generate phone numbers and emails\n",
    "phones = []\n",
    "emails = []\n",
    "\n",
    "for i in range(4):\n",
    "    # Generate phone with specific pattern\n",
    "    phone = fake.numerify(text=phone_patterns[i])\n",
    "    phones.append(phone)\n",
    "\n",
    "    # Generate email with specific TLD\n",
    "    email = fake.user_name() + \"@\" + fake.domain_word() + email_tlds[i]\n",
    "    emails.append(email)\n",
    "\n",
    "# Define sentence structures\n",
    "sentence_structures = [\n",
    "    lambda p, e: f\"Contact me at {e} or {p} to resolve this issue.\",\n",
    "    lambda p, e: f\"You can reach me by phone ({p}) or email ({e}) anytime.\",\n",
    "    lambda p, e: f\"My contact details: {e} and {p}.\",\n",
    "    lambda p, e: f\"Feel free to call {p} or email {e} for assistance.\"\n",
    "]\n",
    "\n",
    "# Create DataFrame directly\n",
    "messages = [sentence_structures[i](phones[i], emails[i]) for i in range(4)]\n",
    "df_tickets = pd.DataFrame({\n",
    "    \"ticket_id\": range(4),\n",
    "    \"message\": messages\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the display option to show the full width of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the tickets dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tickets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Regex: Basic Pattern Extraction\n",
    "\n",
    "Regular expressions (regex) are patterns that match text based on rules. They excel at finding structured data like emails, phone numbers, and dates in unstructured text.\n",
    "\n",
    "### Extract Email Addresses\n",
    "\n",
    "Start with a simple pattern that matches basic email formats, including:\n",
    "\n",
    "- Username: `[a-z]+` - One or more lowercase letters (e.g. `maria95`)\n",
    "- Separator: `@` - Literal `@` symbol\n",
    "- Domain: `[a-z]+` - One or more lowercase letters (e.g. `gmail` or `outlook`)\n",
    "- Dot: `\\.` - Literal dot (escaped)\n",
    "- Extension: `(?:org|net|com|io)` - Match specific extensions (e.g. `.com`, `.org`, `.io`, `.net`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Match basic email format: letters@domain.extension\n",
    "email_pattern = r'[a-z]+@[a-z]+\\.(?:org|net|com|io)'\n",
    "\n",
    "df_tickets['emails'] = df_tickets['message'].apply(\n",
    "    lambda x: re.findall(email_pattern, x)\n",
    ")\n",
    "\n",
    "df_tickets[['message', 'emails']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pattern works for simple emails but misses variations with:\n",
    "\n",
    "- Other characters in the username such as numbers, dots, underscores, plus signs, or hyphens\n",
    "- Other characters in the domain such as numbers, dots, or hyphens\n",
    "- Other extensions that are not `.com`, `.org`, `.io`, or `.net`\n",
    "\n",
    "Let's expand the pattern to handle more formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle emails with numbers, dots, underscores, hyphens, plus signs\n",
    "improved_email = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "\n",
    "df_tickets['emails_improved'] = df_tickets['message'].apply(\n",
    "    lambda x: re.findall(improved_email, x)\n",
    ")\n",
    "\n",
    "df_tickets[['message', 'emails_improved']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The improved pattern successfully extracts all emails from the tickets! Let's move on to extracting phone numbers.\n",
    "\n",
    "### Extract Phone Numbers\n",
    "\n",
    "Common phone number formats are:\n",
    "\n",
    "- `(XXX)XXX-XXXX` - With parentheses\n",
    "- `XXX-XXX-XXXX` - Without parentheses\n",
    "- `XXX XXX XXXX` - With spaces\n",
    "- `XXX.XXX.XXXX` - With dots\n",
    "\n",
    "To handle all four phone formats, we can use the following pattern:\n",
    "\n",
    "- `\\(?` - Optional opening parenthesis\n",
    "- `\\d{3}` - Exactly 3 digits (area code)\n",
    "- `[-.\\s]?` - Optional hyphen, dot, or space\n",
    "- `\\)?` - Optional closing parenthesis\n",
    "- `\\d{3}` - Exactly 3 digits (prefix)\n",
    "- `[-.\\s]?` - Optional hyphen, dot, or space\n",
    "- `\\d{3,4}` - Exactly 3 or 4 digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define phone pattern\n",
    "phone_pattern = r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]\\d{4}'\n",
    "\n",
    "df_tickets['phones'] = df_tickets['message'].apply(\n",
    "    lambda x: re.findall(phone_pattern, x)\n",
    ")\n",
    "\n",
    "df_tickets[['message', 'phones']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We are able to extract all phone numbers from the tickets!\n",
    "\n",
    "While these patterns works, they are difficult to understand and modify for someone who is not familiar with regex.\n",
    "\n",
    "> ðŸ“– Readable code reduces maintenance burden and improves team productivity. [Production-Ready Data Science](https://codecut.ai/production-ready-data-science/) provides detailed guidance on writing production-quality code.\n",
    "\n",
    "In the next section, we will use pregex to build more readable patterns.\n",
    "\n",
    "## pregex: Build Readable Patterns\n",
    "\n",
    "[pregex](https://github.com/manoss96/pregex) is a Python library that lets you build regex patterns using readable Python syntax instead of regex symbols. It breaks complex patterns into self-documenting components that clearly express validation logic.\n",
    "\n",
    "Install pregex:\n",
    "\n",
    "```bash\n",
    "pip install pregex\n",
    "```\n",
    "\n",
    "### Extract Email Addresses\n",
    "\n",
    "Let's extract emails using pregex's readable components.\n",
    "\n",
    "In the code, we will use the following components:\n",
    "\n",
    "- Username: `OneOrMore(AnyButWhitespace())` - Any letters but whitespace (`maria95`)\n",
    "- Separator: `@` - Literal @ symbol\n",
    "- Domain name: `OneOrMore(AnyButWhitespace())` - Any letters but whitespace (`gmail` or `outlook`)\n",
    "- Extension: `Either(\".com\", \".org\", \".io\", \".net\")` - Match specific extensions (`.com`, `.org`, `.io`, `.net`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pregex.core.classes import AnyButWhitespace\n",
    "from pregex.core.quantifiers import OneOrMore\n",
    "from pregex.core.operators import Either\n",
    "\n",
    "username = OneOrMore(AnyButWhitespace())\n",
    "at_symbol = \"@\"\n",
    "domain_name = OneOrMore(AnyButWhitespace())\n",
    "extension = Either(\".com\", \".org\", \".io\", \".net\")\n",
    "\n",
    "email_pattern = username + at_symbol + domain_name + extension\n",
    "\n",
    "# Extract emails\n",
    "df_tickets[\"emails_pregex\"] = df_tickets[\"message\"].apply(\n",
    "    lambda x: email_pattern.get_matches(x)\n",
    ")\n",
    "\n",
    "df_tickets[[\"message\", \"emails_pregex\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that we are able to extract the emails from the tickets!\n",
    "\n",
    "pregex transforms pattern matching from symbol decoding into readable code. `OneOrMore(username_chars)` communicates intent more clearly than `[a-zA-Z0-9._%+-]+`, reducing the time teammates spend understanding and modifying validation logic.\n",
    "\n",
    "For more pregex examples including URLs and time patterns, see [PRegEx: Write Human-Readable Regular Expressions in Python](https://codecut.ai/pregex-write-human-readable-regular-expressions-in-python-2/).\n",
    "\n",
    "### Extract Phone Numbers\n",
    "\n",
    "Now extract phone numbers with multiple components:\n",
    "\n",
    "- First three digits: `Optional(\"(\") + Exactly(AnyDigit(), 3) + Optional(\")\")`\n",
    "- Separator: `Either(\" \", \"-\", \".\")`\n",
    "- Second three digits: `Exactly(AnyDigit(), 3)`\n",
    "- Last four digits: `Exactly(AnyDigit(), 4)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pregex.core.classes import AnyDigit\n",
    "from pregex.core.quantifiers import Optional, Exactly\n",
    "from pregex.core.operators import Either\n",
    "\n",
    "# Build phone pattern using pregex\n",
    "first_three = Optional(\"(\") + Exactly(AnyDigit(), 3) + Optional(\")\")\n",
    "separator = Either(\" \", \"-\", \".\")\n",
    "second_three = Exactly(AnyDigit(), 3)\n",
    "last_four = Exactly(AnyDigit(), 4)\n",
    "\n",
    "phone_pattern = first_three + Optional(separator) + second_three + separator + last_four\n",
    "\n",
    "# Extract phone numbers\n",
    "df_tickets['phones_pregex'] = df_tickets['message'].apply(\n",
    "    lambda x: phone_pattern.get_matches(x)\n",
    ")\n",
    "\n",
    "df_tickets[['message', 'phones_pregex']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your system requires the raw regex pattern, you can get it with `get_compiled_pattern()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compiled email pattern:\", email_pattern.get_compiled_pattern().pattern)\n",
    "print(\"Compiled phone pattern:\", phone_pattern.get_compiled_pattern().pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create tickets with embedded comments and variable whitespace\n",
    "tickets = [\n",
    "    \"Ticket: 1000 | Priority: High | Assigned: John Doe # escalated\",\n",
    "    \"Ticket: 1001  |  Priority: Medium  |  Assigned: Maria Garcia # team lead\",\n",
    "    \"Ticket:1002| Priority:Low |Assigned:Alice Smith # non-urgent\",\n",
    "    \"Ticket: 1003 | Priority: High | Assigned: Bob Johnson # on-call\"\n",
    "]\n",
    "\n",
    "df_tickets = pd.DataFrame({'ticket': tickets})\n",
    "df_tickets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tickets include embedded Python-style comments `# comment` at the end and inconsistent whitespace around separators.\n",
    "\n",
    "Let's create a pattern to extract the first ticket header:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pregex.core.quantifiers import OneOrMore\n",
    "from pregex.core.classes import AnyDigit, AnyLetter, AnyWhitespace\n",
    "from pregex.core.groups import Capture\n",
    "\n",
    "\n",
    "sample_ticket = \"Ticket: 1000 | Priority: High | Assigned: John Doe # escalated\"\n",
    "\n",
    "# Define patterns with Capture to extract just the values\n",
    "whitespace = AnyWhitespace()\n",
    "ticket_id_pattern = \"Ticket:\" + whitespace + Capture(OneOrMore(AnyDigit()))\n",
    "priority_pattern = \"Priority:\" + whitespace + Capture(OneOrMore(AnyLetter()))\n",
    "name_pattern = (\n",
    "    \"Assigned:\"\n",
    "    + whitespace\n",
    "    + Capture(OneOrMore(AnyLetter()) + \" \" + OneOrMore(AnyLetter()))\n",
    ")\n",
    "\n",
    "# Define separator pattern (whitespace around pipe)\n",
    "separator = whitespace + \"|\" + whitespace\n",
    "\n",
    "# Combine all patterns with separators\n",
    "ticket_pattern = (\n",
    "    ticket_id_pattern\n",
    "    + separator\n",
    "    + priority_pattern\n",
    "    + separator\n",
    "    + name_pattern\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we use the `Capture` to extract the ticket components.\n",
    "\n",
    "Next, define a function to extract the ticket components from the captured components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticket_components(ticket_string, ticket_pattern):\n",
    "    \"\"\"Extract ticket components from a ticket string.\"\"\"\n",
    "    try:\n",
    "        captures = ticket_pattern.get_captures(ticket_string)[0]\n",
    "        return pd.Series(\n",
    "            {\n",
    "                \"ticket_id\": captures[0],\n",
    "                \"priority\": captures[1],\n",
    "                \"assigned\": captures[2],\n",
    "            }\n",
    "        )\n",
    "    except IndexError:\n",
    "        return pd.Series(\n",
    "            {\"ticket_id\": None, \"priority\": None, \"assigned\": None}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function with the pattern defined above to the sample ticket. Here we use the `partial` function to create a partial function that binds the pattern to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = get_ticket_components(sample_ticket, ticket_pattern)\n",
    "print(components.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract individual components using the function\n",
    "df_pregex = df_tickets.copy()\n",
    "components_df = df_pregex[\"ticket\"].apply(get_ticket_components, ticket_pattern=ticket_pattern)\n",
    "\n",
    "df_pregex = df_pregex.assign(**components_df)\n",
    "\n",
    "df_pregex[[\"ticket_id\", \"priority\", \"assigned\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pregex misses Tickets 1 and 2 because `AnyWhitespace()` only matches a single space, while those rows use inconsistent spacing around the separators.\n",
    "\n",
    "Making pregex patterns flexible enough for variable formatting requires adding optional quantifiers to the whitespace pattern so that it can match zero or more spaces around the separators.\n",
    "\n",
    "As these fixes accumulate, pregex's readability advantage diminishes, and you end up with code that's as hard to understand as raw regex but more verbose.\n",
    "\n",
    "When parsing structured data with consistent patterns but varying details, pyparsing provides more robust handling than regex.\n",
    "\n",
    "## pyparsing: Parse Structured Ticket Headers\n",
    "\n",
    "Unlike regex's pattern matching approach, [pyparsing](https://github.com/pyparsing/pyparsing) lets you define grammar rules using Python classes, making parsing logic explicit and maintainable.\n",
    "\n",
    "Install pyparsing:\n",
    "\n",
    "```bash\n",
    "pip install pyparsing\n",
    "```\n",
    "\n",
    "Let's parse the complete structure with pyparsing, including:\n",
    "\n",
    "- Ticket ID: `Word(nums)` - One or more digits (e.g. `1000`)\n",
    "- Priority: `Word(alphas)` - One or more letters (e.g. `High`)\n",
    "- Name: `Word(alphas) + Word(alphas)` - First and last name (e.g. `John Doe`)\n",
    "\n",
    "We will also use the `pythonStyleComment` to ignore Python-style comments throughout parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyparsing import Word, alphas, nums, Literal, pythonStyleComment\n",
    "\n",
    "# Define grammar components\n",
    "ticket_num = Word(nums)\n",
    "priority = Word(alphas)\n",
    "name = Word(alphas) + Word(alphas)\n",
    "\n",
    "# Define complete structure\n",
    "ticket_grammar = (\n",
    "    \"Ticket:\"\n",
    "    + ticket_num\n",
    "    + \"|\"\n",
    "    + \"Priority:\"\n",
    "    + priority\n",
    "    + \"|\"\n",
    "    + \"Assigned:\"\n",
    "    + name\n",
    ")\n",
    "\n",
    "# Automatically ignore Python-style comments throughout parsing\n",
    "ticket_grammar.ignore(pythonStyleComment)\n",
    "\n",
    "sample_ticket = \"Ticket: 1000 | Priority: High | Assigned: John Doe # escalated\"\n",
    "sample_result = ticket_grammar.parse_string(sample_ticket)\n",
    "print(sample_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define complete structure\n",
    "ticket_grammar = (\n",
    "    \"Ticket:\"\n",
    "    + ticket_num(\"ticket_id\")\n",
    "    + \"|\"\n",
    "    + \"Priority:\"\n",
    "    + priority(\"priority\")\n",
    "    + \"|\"\n",
    "    + \"Assigned:\"\n",
    "    + name(\"assigned\")\n",
    ")\n",
    "\n",
    "# Automatically ignore Python-style comments throughout parsing\n",
    "ticket_grammar.ignore(pythonStyleComment)\n",
    "\n",
    "sample_ticket = \"Ticket: 1000 | Priority: High | Assigned: John Doe # escalated\"\n",
    "sample_result = ticket_grammar.parse_string(sample_ticket)\n",
    "\n",
    "# Access the components by name\n",
    "print(\n",
    "    f\"Ticket ID: {sample_result.ticket_id}\",\n",
    "    f\"Priority: {sample_result.priority}\",\n",
    "    f\"Assigned: {' '.join(sample_result.assigned)}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse all tickets and create columns\n",
    "def parse_ticket(ticket, ticket_grammar):\n",
    "    result = ticket_grammar.parse_string(ticket)\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"ticket_id\": result.ticket_id,\n",
    "            \"priority\": result.priority,\n",
    "            \"assigned\": \" \".join(result.assigned),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "df_pyparsing = df_tickets.copy()\n",
    "components_df_pyparsing = df_pyparsing[\"ticket\"].apply(parse_ticket, ticket_grammar=ticket_grammar)\n",
    "df_pyparsing = df_pyparsing.assign(**components_df_pyparsing)\n",
    "\n",
    "df_pyparsing[[\"ticket_id\", \"priority\", \"assigned\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output looks good!\n",
    "\n",
    "Let's try to parse some more structured data with pyparsing.\n",
    "\n",
    "### Extract Code Blocks from Markdown\n",
    "\n",
    "Use `SkipTo` to extract Python code between code block markers without complex regex patterns like `r'```python(.*?)```'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyparsing import Literal, SkipTo\n",
    "\n",
    "code_start = Literal(\"```python\")\n",
    "code_end = Literal(\"```\")\n",
    "\n",
    "code_block = code_start + SkipTo(code_end)(\"code\") + code_end\n",
    "\n",
    "markdown = \"\"\"```python\n",
    "def hello():\n",
    "    print(\"world\")\n",
    "```\"\"\"\n",
    "\n",
    "result = code_block.parse_string(markdown)\n",
    "print(result.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyparsing import nested_expr\n",
    "\n",
    "# Default: parentheses\n",
    "nested_list = nested_expr()\n",
    "result = nested_list.parse_string(\"((2 + 3) * (4 - 1))\")\n",
    "print(result.as_list())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
