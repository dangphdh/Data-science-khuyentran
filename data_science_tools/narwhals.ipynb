{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"date\": [datetime(2020, 1, 1), datetime(2020, 1, 8), datetime(2020, 2, 3)],\n",
    "        \"price\": [1, 4, 3],\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_aggregate_pandas(user_df):\n",
    "    return user_df.resample(\"MS\", on=\"date\")[[\"price\"]].mean()\n",
    "\n",
    "monthly_aggregate_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Dataframe-agnostic data science\n",
    "\n",
    "\n",
    "## Bad solution: just convert to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_aggregate_bad(user_df):\n",
    "    if isinstance(user_df, pd.DataFrame):\n",
    "        df = user_df\n",
    "    elif isinstance(user_df, pl.DataFrame):\n",
    "        df = user_df.to_pandas()\n",
    "    elif isinstance(user_df, duckdb.DuckDBPyRelation):\n",
    "        df = user_df.df()\n",
    "    elif isinstance(user_df, pa.Table):\n",
    "        df = user_df.to_pandas()\n",
    "    elif isinstance(user_df, pyspark.sql.dataframe.DataFrame):\n",
    "        df = user_df.toPandas()\n",
    "    else:\n",
    "        raise TypeError(\"Unsupported DataFrame type: cannot convert to pandas\")\n",
    "\n",
    "    return df.resample(\"MS\", on=\"date\")[[\"price\"]].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"date\": [datetime(2020, 1, 1), datetime(2020, 1, 8), datetime(2020, 2, 3)],\n",
    "    \"price\": [1, 4, 3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "pandas_df = pd.DataFrame(data)\n",
    "monthly_aggregate_bad(pandas_df)\n",
    "\n",
    "# polars\n",
    "polars_df = pl.DataFrame(data)\n",
    "monthly_aggregate_bad(polars_df)\n",
    "\n",
    "# duckdb\n",
    "duckdb_df = duckdb.from_df(pandas_df)\n",
    "monthly_aggregate_bad(duckdb_df)\n",
    "\n",
    "# pyspark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "monthly_aggregate_bad(spark_df)\n",
    "\n",
    "# pyarrow\n",
    "arrow_table = pa.table(data)\n",
    "monthly_aggregate_bad(arrow_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Unmaintainable solution: different branches for each library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_aggregate_unmaintainable(user_df):\n",
    "    if isinstance(user_df, pd.DataFrame):\n",
    "        result = user_df.resample(\"MS\", on=\"date\")[[\"price\"]].mean()\n",
    "    elif isinstance(user_df, pl.DataFrame):\n",
    "        result = (\n",
    "            user_df.group_by(pl.col(\"date\").dt.truncate(\"1mo\"))\n",
    "            .agg(pl.col(\"price\").mean())\n",
    "            .sort(\"date\")\n",
    "        )\n",
    "    elif isinstance(user_df, pyspark.sql.dataframe.DataFrame):\n",
    "        result = (\n",
    "            user_df.withColumn(\"date_month\", F.date_trunc(\"month\", F.col(\"date\")))\n",
    "            .groupBy(\"date_month\")\n",
    "            .agg(F.mean(\"price\").alias(\"price_mean\"))\n",
    "            .orderBy(\"date_month\")\n",
    "        )\n",
    "    # TODO: more branches for DuckDB, PyArrow, Dask, etc... :sob:\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "monthly_aggregate_unmaintainable(pandas_df)\n",
    "\n",
    "# polars\n",
    "monthly_aggregate_unmaintainable(polars_df)\n",
    "\n",
    "# pyspark\n",
    "monthly_aggregate_unmaintainable(spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Best solution: Narwhals as a unified dataframe interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import narwhals as nw\n",
    "from narwhals.typing import IntoFrameT\n",
    "\n",
    "\n",
    "def monthly_aggregate(user_df: IntoFrameT) -> IntoFrameT:\n",
    "    return (\n",
    "        nw.from_native(user_df)\n",
    "        .group_by(nw.col(\"date\").dt.truncate(\"1mo\"))\n",
    "        .agg(nw.col(\"price\").mean())\n",
    "        .sort(\"date\")\n",
    "        .to_native()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "monthly_aggregate(pandas_df)\n",
    "\n",
    "# polars\n",
    "monthly_aggregate(polars_df)\n",
    "\n",
    "# duckdb\n",
    "monthly_aggregate(duckdb_df)\n",
    "\n",
    "# pyarrow\n",
    "monthly_aggregate(arrow_table)\n",
    "\n",
    "# pyspark\n",
    "monthly_aggregate(spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Bonus - can we generate SQL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlframe.duckdb import DuckDBSession\n",
    "\n",
    "sqlframe = DuckDBSession()\n",
    "sqlframe_df = sqlframe.createDataFrame(pandas_df)\n",
    "sqlframe_result = monthly_aggregate(sqlframe_df)\n",
    "print(sqlframe_result.sql(dialect=\"databricks\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
